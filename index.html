
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>optimal experiment design for webppl</title>

    <link rel="stylesheet" href="http://webppl.org/bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="http://webppl.org/bower_components/bootstrap/dist/css/bootstrap-theme.min.css">
    <link rel="stylesheet" href="http://dippl.org/node_modules/codemirror/lib/codemirror.css">
    <link rel="stylesheet" href="http://dippl.org/node_modules/codemirror/theme/neat.css">
    <!--<link rel="stylesheet" href="http://dippl.org/assets/css/code.css"> -->
    <link rel="stylesheet" href="./demo_web/code.css">
    <link rel="stylesheet" href="http://webppl.org/webppl.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js"></script>
    <script src="http://dippl.org/bower_components/jquery-autosize/jquery.autosize.min.js"></script>      
    <script src="http://dippl.org/bower_components/react/JSXTransformer.js"></script>
    <script src="http://dippl.org/bower_components/react/react-with-addons.min.js"></script>
    <script src="http://dippl.org/bower_components/showdown/compressed/showdown.js"></script>
    <script src="http://dippl.org/node_modules/codemirror/lib/codemirror.js"></script>
    <script src="http://dippl.org/bower_components/d3/d3.min.js"></script>
    <script src="http://dippl.org/bower_components/dimple/dist/dimple.v2.1.0.js"></script>
    <script src="http://dippl.org/bower_components/underscore/underscore.js"></script>    
    <script src="http://dippl.org/node_modules/codemirror/mode/javascript/javascript.js"></script>
    <script src="http://dippl.org/assets/js/cm-folding.js"></script>
    <script src="http://dippl.org/assets/js/cm-comments.js"></script>
    <!--<script src="http://webppl.org/initializeEditor.js"></script>-->
    <script src="http://dippl.org/assets/js/editor.js" type="text/jsx"></script>        
    <!--<script src="http://dippl.org/assets/js/webppl.min.js"></script>-->
    <script src="./demo_web/custom.js"></script>
    <!-- <script src="./demo_web/webppl.js"></script> -->
    <script src="./demo_web/webppl.min.js"></script>
    <script src="./demo_web/oed.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
<body>

<div class="container">
<div class="header clearfix">
<nav>
<ul class="nav nav-pills pull-right">
<li role="presentation"><a href="http://github.com/lydaniel/oed_js">On Github</a></li>
</ul>
</nav>
<h3 class="logo"><span class="logo-tagline hidden-xs">Optimal experiment design for WebPPL </span></h3>
</div>

<h2> Optimal experiment design for WebPPL </h2>

<p> This page presents an optimal experiment design (OED) interface for <a href="https://github.com/probmods/webppl">WebPPL</a>, a Javascript-based probabilistic programming language, and illustrates its uses and applications in a series of examples.

<h2> Basic usage </h2>

<p> This introductory example illustrates a simple use case for designing experiments to differentiate between a truncated geometric distribution and a binomial distribution. 

<p> The basic framework of OED is divided into two components. The first task is to define the candidate models to be differentiated using experiment design. Each model needs to be defined as an argumentless function for the subsequent WebPPL inference routines (<code>geom</code>). However, as the models depend on choice of experiments, we create an argument-based wrapper (<code>geom_erp</code>) that takes the experiment as a parameter, executes an inference routine in WebPPL, and returns an Elementary Random Primitive (ERP), which is a data structure that summarizes the probability distribution of a random variables. 

<p> The second task is to execute the models for a specific choice of experiment and compute the information gain using the OED interface. We call <code>OED()</code> with an object argument that summarizes the model and experiment spaces: the <code>models</code> property is an array of candidate models; the <code>model_prior</code> property is an array that describes the prior model belief or the confidence that the corresponding candidate model is the correct one (this will default to a uniform distribution if left undefined); and <code>experiments</code> property is an array of experiments to iterate over to compute the information gain.

<p> In the following example, we use OED to compute the information gain between a truncated geometric distribution and a binomial distribution, where the experiment is the respective success probability. We will compute the information gain for the experiment where <code>p=0.2</code>, and with a model belief of 0.4 and 0.6, for the truncated geometric distribution and binomial distribution, respectively.

<pre><code>///fold: model parameters
var support_size = 10;
///

// Define candidate models
var geom_erp = function(p) {
  var geom = function() {return flip(p) ? 0 : 1+geom();};
  return Enumerate(geom, support_size+1);
};

var bin_erp = function(p) {
  var bin = function() {return binomial(p, support_size);};
  return Enumerate(bin);
};

// Execute models
var expt = 0.2;
var data = OED({models: [geom_erp, bin_erp], 
                models_prior: [0.4, 0.6],
                experiments: [expt]})
print(data)
</code></pre>

<p> To understand the applications of OED, we begin by analyzing the distributions of both models: these two distributions are fairly similar and a likely response does not efficiently differentiate the models. As a result, the expected information gain from this experiment is 0.1001 nats.

<p> In the next example, the experiment will be changed to <code>p=0.7</code>. 

<pre><code>///fold: candidate models
var support_size = 10;

// Define candidate models
var geom_erp = function(p) {
  var geom = function() {return flip(p) ? 0 : 1+geom();};
  return Enumerate(geom, support_size+1);
};

var bin_erp = function(p) {
  var bin = function() {return binomial(p, support_size);};
  return Enumerate(bin);
};
///

// Execute models
var expt = 0.7;
var data = OED({models: [geom_erp, bin_erp], 
                models_prior: [0.4, 0.6],
                experiments: [expt]})
print(data)
</code></pre>

<p> This experiment is significantly better at disambiguating the models as the two distributions are separated by a large margin. The truncated geometric distribution predicts responses with low values, while the binomial distribution predicts responses with high values. Thus, it is easy to determine the underlying model from any particular response. The expected information gain is 0.6461 nats, which is higher than the first experiment, denoting that it is better at differentiating the models.

<h2> Models of randomness judgements </h2>

<p> This example illustrates a use case for designing a series of experiments for probabilistic models of cognition. We present two simple models that attempt understand how people judge randomness.

<p> Imagine that you are asked to judge whether a sequence of coin flips came from a fair coin or a trick (weighted) coin. The sequence 'TTTTT' probably strikes you as almost certainly a trick, while the sequence 'THHTH' probably strikes you as likely coming from a fair coin. The sequence 'HHHTT' may seem more ambiguous. 

<p> In this example, we will design four flip coin sequences to differentiate between two models. Rather than asking for a direct judgement of fairness, we ask for the probability that the next flip from the same coin will be heads.

<p> The first model, <code>bias_coin</code>, assumes that the coin is weighted with some unknown bias, and each coin flip is independent from each other. The model internally infers the bias based on the sequence, and then uses the inferred bias to predict the next coin flip.

<p> The second model, <code>markov_coin</code>,  assumes that the coin is generated by a Markov process, where each coin flip depends on the previous coin flip. The model internally infers the transition probability, and then uses the inferred transition probability, along the coin sequence, to predict the next coin flip.

<p> The list of four flip coin sequences are enumerated by hand, we compute the expected information gain for each of the coin sequences.

<pre><code>///fold: model parameters and helper functions
var coin_prior     = [0.01, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.99];
var coin_prior_pmf = [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00];
var categorical = function(v,p) {return v[discrete(p)];}
///fold

// Bias coin model
var bias_coin_erp = function(sequence) {
  var bias_coin = function() {
    var inferred_coin_erp = Enumerate(function() {
      var coin_p = categorical(coin_prior, coin_prior_pmf);
      var sequence_factor = sum(map(function(x) {
                                      return (x == '1') ? Math.log(coin_p) : 
                                                          Math.log(1-coin_p);}, 
                                sequence));
      factor(sequence_factor);
      return coin_p;
    });

    var expected_coin_p = expectation(inferred_coin_erp);
    return flip(expected_coin_p);
  };

  return Enumerate(bias_coin);
};

// Markov coin model
var markov_coin_erp = function(sequence) {
  var markov_coin = function() {
    var inferred_coin_erp = Enumerate(function() {
      var transition_p = categorical(coin_prior, coin_prior_pmf);
      var sequence_factor = sum(map2(function(x,y) {
                                       return (x == y) ? Math.log(1-transition_p) : 
                                                          Math.log(transition_p);}, 
                                sequence.slice(0,sequence.length-1), 
                                sequence.slice(1,sequence.length)));
      factor(sequence_factor);
      return transition_p;
    });

    var expected_coin_p = expectation(inferred_coin_erp, 
                                      function(x) {return (last(sequence) == '1') ? 
                                                          1-x : x;});
    return flip(expected_coin_p);
  };

  return Enumerate(markov_coin);
};

// Execute the models and compute the information gain
var expt_list= ['0000', '0001', '0010', '0011', '0100', '0101', '0110', '0111', 
                '1000', '1001', '1010', '1011', '1100', '1101', '1110', '1111'];

var data = OED({models: [bias_coin_erp, markov_coin_erp], 
                experiments: expt_list})
print(data)
</code></pre>

<p> The results of the experiment design should agree with our intuitions. The most informative experiments are the symmetric pair 'HTHT' and 'THTH', since the <code>markov_coin</code> model strongly favors alternating coin flips while the <code>bias_coin</code> infers a fair weighting and does not favor either outcome. Following the same logic, the least informative experiments are the symmetric pair 'HHHH' and 'TTTT', since both models predict the same outcome. 

<p> Try clicking on the bars in the plot to see the response distributions of the corresponding experiments. This will allow us to easily get a deeper understanding of why specific experiments vary in their ability to differentiate the models.

<h2> Social reasoning and enumeration of experiment spaces</h2>

<p> This example illustrates how experiment spaces can be easily enumerated for exploring and understanding the behavior of candidate models. We present three cognitive models that attempt to capture how people reason in a social setting. 

<p> Imagine that you are at the race track, looking to wager on race outcomes between a two horse race. You are able to watch a series of races and observe the horses in action before betting. However, you are also able gather information from your fellow bettors - you are able to see their wager and you know how many races they witnessed, although you cannot recover the individual outcomes of their races. How should you place your bet, given these two streams of information?

<p> We will design experiments based on four parameters: the number of directly observed races, the number of directly observed wins, the number of races observed by your fellow better, and the wager of your fellow better. We ask for the probability that the horse will win the next race, measured on an eleven point scale.

<p> We aim to differentiate between three models of social reasoning. The first model, <code>arrogant_reasoner</code>, only reasons about the direct observations and disregards any socially obtained data. The model determines the probability of a win by assuming a binomial distribution and inferring the model parameters.

<p> The second model, <code>deferent_reasoner</code>, only reasons using the socially obtained data and disregards any direct observations. The model determines the probability of a win by using a generative model of the fellow bettor's decision making process and conditioning on the fellow better's wager.

<p> The third model, <code>observant_reasoner</code>, reasons using both the directly observations as well as the socially obtained data. The model determines the probability of a win by conditioning on the direct binomial distribution as well as the fellow better's wager, while attributing qualities such as reliability to the fellow better.

<p> In this example, we will consider the experiment space where the number of directly observed races is 5, the number of directly observed wins ranges from 0 to 5, the number of races observed by the fellow better is selected from the set {2, 5, 10, 30}, and the fellow better always wagers on a win. We create an array for each of the four parameters and then use <code>oed.product</code> to compute the Cartesian product of these sets. This function, and other combinatoric functions such as <code>oed.permutations</code> and <code>oed.combinations</code> allows us to enumerate over the space of experiments easily.

<pre><code>///fold: categorical priors
var skill_prior     = [0.01, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.99];
var skill_prior_pmf = [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00];

var decision_prior     = [0.000, 10.000];
var decision_prior_pmf = [0.250,  0.750];

var categorical = function(v,p) {return v[discrete(p)];}
///

///fold: bettor's decision making model
var bet_erp = function(num, win) {
  var bet = function() {
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    var test_decision = categorical(decision_prior, decision_prior_pmf);
    factor((binomial(test_skill, num) == win) ? 0 : -Infinity);
    return flip(Math.exp(test_decision*test_skill)/
                (Math.exp(test_decision*test_skill) + Math.exp(test_decision*(1-test_skill))));
  };

  return Enumerate(bet);
};
///

// Arrogant reasoner model
var arrogant_reasoner_erp = function(params) {
  var l_num = params[0]; var l_win = params[1];
  var t_num = params[2]; var t_bet = params[3]; 

  var arrogant_reasoner = function() {
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    factor((binomial(test_skill, l_num) == l_win) ? 0 : -Infinity);
    return test_skill;
  };
  
  return Enumerate(arrogant_reasoner);
};

// Deferent reasoner model
var deferent_reasoner_erp = function(params) {
  var l_num = params[0]; var l_win = params[1];
  var t_num = params[2]; var t_bet = params[3]; 

  var deferent_reasoner = function() {
    var t_bet_tf = (t_bet == 1);
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    var t_win = binomial(test_skill, t_num);
    var test_bet = sample(bet_erp(t_num, t_win));
    factor((test_bet == t_bet_tf) ? 0 : -Infinity);
    return test_skill;
  };
  
  return Enumerate(deferent_reasoner);
};

// Observant reasoner model
var observant_reasoner_erp = function(params) {
  var l_num = params[0]; var l_win = params[1];
  var t_num = params[2]; var t_bet = params[3]; 

  var observant_reasoner = function() {
    var t_bet_tf = (t_bet == 1);
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    var t_win = binomial(test_skill, t_num);
    var test_bet = sample(bet_erp(t_num, t_win))
    factor(((binomial(test_skill, l_num) == l_win) && 
            (test_bet == t_bet_tf)) ? 0 : -Infinity);
    return test_skill;
  };
  
  return Enumerate(observant_reasoner);
};

// List of experiment parameters 
var l_direct_obs = [5];
var l_direct_win = [0,1,2,3,4,5];
var l_social_obs = [2,5,10,30];
var l_social_bet = [1];

var expt_list = oed.list_product([l_direct_obs, l_direct_win, 
                                  l_social_obs, l_social_bet]);

// Execute the models and compute the information gain
var data = OED({models: [arrogant_reasoner_erp, deferent_reasoner_erp, 
                         observant_reasoner_erp], 
                experiments: expt_list})
print(data)
</code></pre>

<p> By enumerating over the experiments, we can analyze the effect of each parameter on its ability to differentiate the candidate models. If we click on the optimal experiment, <code>[5,0,30,1]</code>, we can see that it is able to strongly differentiate between the set of arrogant and observant reasoners and the deferent reasoner. This result is intuitive as it introduces the greatest conflict between the two streams of information: the direct observations suggest that the win percentage is low, yet the fellow bettor's behavior suggests that the win percentage is high. As a result, the arrogant reasoner would likely wager on the win, while the deferent reasoner would likely wager on a loss. The observant reasoner would reason that the most likely explaination for this conflict of information is that the fellow better is unreliable and would also likely wager on the win, although with less confidence than the arrogant reasoner. 

<p> By analyzing the distributions of each experiment, we can begin to develop a deeper understanding of these models and answer more complex questions such as: is the information gain more sensitive to the number of directly observed wins or the number of races observed by the fellow bettor, how does the number of races observed by the fellow better affect the ability to discriminate candidate models, or why is directly observing four wins less informative than observing five wins? Try clicking on the experiments to see if you can figure it out.

<h2> Optimal experiment design for a given number of participants </h2>

<p> This example illustrates how the optimal experiment may depend on the number of participants, and it is based on the three social reasoning cognitive models introduced in the previous example. 

<p> To understand how the optimal experiment may depend on the number of participants, consider the following scenario: you are asked to distinguish between one of three models and each participant provides a yes/no response. In the first experiment, the models predict that a participant will respond yes with a probability of 0.98, 0.88, and 0.05, respectively. In the second experiment, the models predict that a participant will respond yes with a probability of 0.3, 0.5, and 0.7, respectively. If you can only ask a single participant, then it is better to run the first experiment and it will definitely differentiate between the first two and the third model. However, the responses from any additional participant provides a minimal increase in information as it is very difficult to differentiate between the first and second model. Conversely, the second experiment provides far less information for a single participant, but is able to better differentiate the models with more participants.

<p> From the previous experiment, we saw that the optimal experiment for a single participant was the condition where there are zero directly observed wins out of five races, and the fellow better sees 30 races and decides to bet. However, is it the still most informative experiment if we are able to survey more than one participant?

<p> For illustrative purposes, we will only consider two experiments. In both experiments, there are five directly observed races, and the fellow better sees 30 races and decides to bet. The experiments differ between the number of directly observed wins, with the outcome of 0 and 1, respectively. We compute the expected information gain for the two experiments as the number of participants range from 0 to 20 by adding an extra <code>num_participants</code> argument to the <code>OED</code> function, which is an array of the number of participants.

<pre><code> ///fold: categorical priors
var skill_prior     = [0.01, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.99];
var skill_prior_pmf = [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00];

var decision_prior     = [0.000, 10.000];
var decision_prior_pmf = [0.250,  0.750];

var categorical = function(v,p) {return v[discrete(p)];}
///

///fold: bettor's decision making model
var bet_erp = function(num, win) {
  var bet = function() {
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    var test_decision = categorical(decision_prior, decision_prior_pmf);
    factor((binomial(test_skill, num) == win) ? 0 : -Infinity);
    return flip(Math.exp(test_decision*test_skill)/
                (Math.exp(test_decision*test_skill) + Math.exp(test_decision*(1-test_skill))));
  };

  return Enumerate(bet);
};
///

///fold: social reasoning models
// Arrogant reasoner model
var arrogant_reasoner_erp = function(params) {
  var l_num = params[0]; var l_win = params[1];
  var t_num = params[2]; var t_bet = params[3]; 

  var arrogant_reasoner = function() {
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    factor((binomial(test_skill, l_num) == l_win) ? 0 : -Infinity);
    return test_skill;
  };
  
  return Enumerate(arrogant_reasoner);
};

// Deferent reasoner model
var deferent_reasoner_erp = function(params) {
  var l_num = params[0]; var l_win = params[1];
  var t_num = params[2]; var t_bet = params[3]; 

  var deferent_reasoner = function() {
    var t_bet_tf = (t_bet == 1);
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    var t_win = binomial(test_skill, t_num);
    var test_bet = sample(bet_erp(t_num, t_win));
    factor((test_bet == t_bet_tf) ? 0 : -Infinity);
    return test_skill;
  };
  
  return Enumerate(deferent_reasoner);
};

// Observant reasoner model
var observant_reasoner_erp = function(params) {
  var l_num = params[0]; var l_win = params[1];
  var t_num = params[2]; var t_bet = params[3]; 

  var observant_reasoner = function() {
    var t_bet_tf = (t_bet == 1);
    var test_skill = categorical(skill_prior, skill_prior_pmf);
    var t_win = binomial(test_skill, t_num);
    var test_bet = sample(bet_erp(t_num, t_win))
    factor(((binomial(test_skill, l_num) == l_win) && 
            (test_bet == t_bet_tf)) ? 0 : -Infinity);
    return test_skill;
  };
  
  return Enumerate(observant_reasoner);
};
///

// List of experiment parameters and number of participants
var expt_list = [[5,0,30,1], [5,1,30,1]];
var npart_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 
                  11, 12, 13, 14, 15, 16, 17, 18, 19, 20];

// Execute the models and compute the information gain
var data = OED({models: [arrogant_reasoner_erp, deferent_reasoner_erp, 
                         observant_reasoner_erp], 
                experiments: expt_list,
                num_participants: npart_list})
print(data)
</code></pre>

<p> The optimal experiment depends on the number of participants, with the transition occuring around the fourth participant. The first experiment, <code>[5,0,30,1]</code>, provides the most conflict between the direct and social observations, and from the analysis in the previous example, we know that it is easy to differentiate pair of arrogant and observant reasoners from the deferent reasoner, especially for a small number of participants. However, this experiment is inefficient at differentiating between the arrogant and observant reasoners with additional participants, as these two distributions are very similar. 

<p> By clicking on the second experiment, <code>[5,0,30,1]</code>, we can determine that it produces more unique distributions at the cost of greater overlap across the joint set. This property makes it difficult to differentiate the models with fewer participants, but is more efficient with additional participants.

<h4>Acknowledgments</h4>
<p>The webppl project is supported by grants from DARPA, under agreement number FA8750-14-2-0009, and the Office of Naval Research, grant number N00014-13-1-0788.</p>

</div>
</div>

<footer class="footer">
<div class="container text-center">
<p>webppl is a <a href="http://cocolab.stanford.edu/">Stanford CoCoLab</a> project</p>
</div>
</footer>

</div> <!-- /container -->

</body>
</html>


